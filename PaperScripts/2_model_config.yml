LeNet:
  activation: relu
  gpu_device: '0'
  inputs_shape:
    x: !!python/tuple
    - 28
    - 28
    - 1
  lr: 0.0005
  optimizer: adam
  pooling: max
  targets_shape:
    y: !!python/tuple
    - 10
MLP:
  activation: relu
  dropout: 0.2
  gpu_device: '0'
  inputs_shape:
    x: !!python/tuple
    - 784
  lr: 0.0005
  optimizer: adam
  targets_shape:
    y: !!python/tuple
    - 10
  units:
  - 512
  - 512
MobileNet:
  alpha: 0.35
  dense_units:
  - 256
  - 256
  optimizer: adam
  weights: imagenet
Model: LeNet
ResNet50:
  dense_units:
  - 256
  - 256
  optimizer: adam
upload:
  upload_name_filter:
  - None
  upload_sparse: 1.0
  upload_strategy: no-compress
